{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import lexApr as lex\n",
    "import CSR, subset\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['empty' 'sadness' 'surprise' 'happiness' 'anger']\n"
     ]
    }
   ],
   "source": [
    "#Open the datasets\n",
    "training_set = \"../Data/train_data_red.csv\"\n",
    "test_set = \"../Data/test_data_red.csv\"\n",
    "val_set = \"../Data/val_data_red.csv\"\n",
    "train_data = pd.read_csv(training_set, engine='python')\n",
    "test_data = pd.read_csv(test_set, engine='python')\n",
    "val_data = pd.read_csv(val_set, engine='python')\n",
    "\n",
    "#dropna drops missing values(not available)\n",
    "train_data = train_data.dropna(axis=0)\n",
    "print (train_data.sentiment.unique())\n",
    "test_data = test_data.dropna(axis=0)\n",
    "\n",
    "#GET THE RAW FEATURES\n",
    "X = train_data.content\n",
    "Xtest = test_data.content\n",
    "#change the value of sentiment from string to int\n",
    "#y = pd.Categorical(pd.factorize(train_data.sentiment)[0])\n",
    "switch = {\n",
    "    'empty': 0,\n",
    "    'sadness':  1,\n",
    "    'neutral':  2,\n",
    "    'surprise':  3,\n",
    "    'happiness':  4,\n",
    "    'anger': 5\n",
    "}\n",
    "y = []\n",
    "for s in train_data.sentiment:\n",
    "    y.append(switch.get(s))\n",
    "\n",
    "ytest = []\n",
    "for s in val_data.sentiment:\n",
    "    ytest.append(switch.get(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the training set\n",
    "X = [re.sub(r'[^\\x00-\\x7f]',r' ',s) for s in X]             #remove non-ascii characters\n",
    "X = [re.sub(r'https?:\\/\\/[^ ]*',r'URL',s) for s in X]       #replace urls\n",
    "#replace the negative or positive emoticons with tags\n",
    "pos_regex = '[:;]-?[)Dp]+|<3'\n",
    "neg_regex = ':-?\\'?[(/Oo]+'\n",
    "X = [re.sub(pos_regex, ' posE ',s) for s in X]\n",
    "X = [re.sub(neg_regex, ' negE ',s) for s in X]\n",
    "\n",
    "X = [re.sub(r'[.,!;?:]+',r'. ',s) for s in X]             #replace seperators for tokenization\n",
    "X = [re.sub(r'#[^ ]*',r'HASHTAG', s) for s in X]          #replace hashtags\n",
    "X = [re.sub(r'@[^ ]*',r'AT_MENTION', s) for s in X]       #replace @-mentions\n",
    "X = [re.sub(\"[^A-Za-z_.' ]+\",r' ', s) for s in X]\n",
    "\n",
    "#For the test set\n",
    "Xtest = [re.sub(r'[^\\x00-\\x7f]',r' ',s) for s in Xtest]             #remove non-ascii characters\n",
    "Xtest = [re.sub(r'https?:\\/\\/[^ ]*',r'URL',s) for s in Xtest]       #replace urls\n",
    "#replace the negative or positive emoticons with tags\n",
    "Xtest = [re.sub(pos_regex, ' posE ',s) for s in Xtest]\n",
    "Xtest = [re.sub(neg_regex, ' negE ',s) for s in Xtest]\n",
    "\n",
    "Xtest = [re.sub(r'[.,!;?:]+',r'. ',s) for s in Xtest]             #replace seperators for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: AT_MENTION i know  i was listenin to bad habit earlier and i started freakin at his part  \n",
      "1: Layin n bed with a headache  ughhhh. waitin on your call. \n",
      "2: Funeral ceremony. gloomy friday. \n",
      "3: I should be sleep.  but im not.  thinking about an old friend who I want.  but he's married now.  damn.   amp.  he wants me  .  scandalous. \n",
      "4: AT_MENTION Charlene my love.  I miss you\n",
      "5: AT_MENTION I'm sorry  at least it's Friday. \n",
      "6: Ugh.  I have to beat this stupid song to get to the next  rude. \n",
      "7: AT_MENTION if u watch the hills in london u will realise what tourture it is because were weeks and weeks late  i just watch itonlinelol\n",
      "8: Got the news\n",
      "9: The storm is here and the electricity is gone\n"
     ]
    }
   ],
   "source": [
    "for i,s in enumerate(X[:10]):\n",
    "    print str(i)+\":\",s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [word_tokenize(s) for s in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ['AT_MENTION', 'i', 'know', 'i', 'was', 'listenin', 'to', 'bad', 'habit', 'earlier', 'and', 'i', 'started', 'freakin', 'at', 'his', 'part']\n",
      "1: ['Layin', 'n', 'bed', 'with', 'a', 'headache', 'ughhhh', '.', 'waitin', 'on', 'your', 'call', '.']\n",
      "2: ['Funeral', 'ceremony', '.', 'gloomy', 'friday', '.']\n",
      "3: ['I', 'should', 'be', 'sleep', '.', 'but', 'im', 'not', '.', 'thinking', 'about', 'an', 'old', 'friend', 'who', 'I', 'want', '.', 'but', 'he', \"'s\", 'married', 'now', '.', 'damn', '.', 'amp', '.', 'he', 'wants', 'me', '.', 'scandalous', '.']\n",
      "4: ['AT_MENTION', 'Charlene', 'my', 'love', '.', 'I', 'miss', 'you']\n",
      "5: ['AT_MENTION', 'I', \"'m\", 'sorry', 'at', 'least', 'it', \"'s\", 'Friday', '.']\n",
      "6: ['Ugh', '.', 'I', 'have', 'to', 'beat', 'this', 'stupid', 'song', 'to', 'get', 'to', 'the', 'next', 'rude', '.']\n",
      "7: ['AT_MENTION', 'if', 'u', 'watch', 'the', 'hills', 'in', 'london', 'u', 'will', 'realise', 'what', 'tourture', 'it', 'is', 'because', 'were', 'weeks', 'and', 'weeks', 'late', 'i', 'just', 'watch', 'itonlinelol']\n",
      "8: ['Got', 'the', 'news']\n",
      "9: ['The', 'storm', 'is', 'here', 'and', 'the', 'electricity', 'is', 'gone']\n"
     ]
    }
   ],
   "source": [
    "for i,s in enumerate(X[:10]):\n",
    "    print str(i)+\":\",s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = [line.rstrip('\\n') for line in open(\"../Data/conjunctions.txt\")]\n",
    "\n",
    "#For the training set\n",
    "XX = []\n",
    "posE_train = []\n",
    "negE_train = []\n",
    "train_len = []\n",
    "for tweet in X:\n",
    "    train_len.append(len(tweet))\n",
    "    tmp = []\n",
    "    s = ''\n",
    "    pose = nege = 0\n",
    "    for word in tweet:\n",
    "        if word == 'posE':\n",
    "            pose += 1\n",
    "        if word == 'negE':\n",
    "            nege += 1\n",
    "\n",
    "        if word in word_list:\n",
    "            if s != '':\n",
    "                tmp.append(s)\n",
    "            tmp.append(word)\n",
    "            s = word\n",
    "        elif word == '.':\n",
    "            if s != '':\n",
    "                tmp.append(s)\n",
    "            s = ''\n",
    "        else:\n",
    "            if s == '':\n",
    "                s += word\n",
    "            else:\n",
    "                s += \" \" + word\n",
    "    if s != '':\n",
    "        tmp.append(s)\n",
    "    XX.append(tmp)\n",
    "    posE_train.append(pose)\n",
    "    negE_train.append(nege)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ['AT_MENTION i know i was listenin to bad habit earlier and i started freakin at his part']\n",
      "1: ['Layin n bed with a headache ughhhh', 'waitin on your call']\n",
      "2: ['Funeral ceremony', 'gloomy friday']\n",
      "3: ['I should be sleep', 'but', 'but im not', 'thinking about an old friend who I want', 'but', \"but he 's married now\", 'damn', 'amp', 'he wants me', 'scandalous']\n",
      "4: ['AT_MENTION Charlene my love', 'I miss you']\n",
      "5: [\"AT_MENTION I 'm sorry at least it 's Friday\"]\n",
      "6: ['Ugh', 'I have to beat this stupid song to get to the next rude']\n",
      "7: ['AT_MENTION', 'if', 'if u watch the hills in london u will realise what tourture it is', 'because', 'because were weeks and weeks late i just watch itonlinelol']\n",
      "8: ['Got the news']\n",
      "9: ['The storm is here and the electricity is gone']\n"
     ]
    }
   ],
   "source": [
    "for i,s in enumerate(XX[:10]):\n",
    "    print str(i)+\":\",s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
